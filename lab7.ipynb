{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuaSXjDkRwg9",
        "outputId": "4c9d1ed1-2c71-41b9-f4a2-8ccfd5b80460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: NLTK in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from NLTK) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from NLTK) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from NLTK) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from NLTK) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install NLTK"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import names\n",
        "import random\n",
        "\n",
        "# Tải dữ liệu cần thiết\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('names')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Xx-9rkR6yR",
        "outputId": "24b67e45-86f6-45ac-e07e-fd439f91a9bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "print(\"Danh sách các tập trong corpus Gutenberg:\")\n",
        "print(gutenberg.fileids())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTOF0Ji1SEfc",
        "outputId": "56ddb654-8cce-49eb-ca5d-9d548fa3a8e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Danh sách các tập trong corpus Gutenberg:\n",
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDanh sách stopword tiếng Anh:\")\n",
        "print(stopwords.words('english'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cAMIs8fSHFK",
        "outputId": "df7c10c9-5b01-4180-85b9-39e5c9984b23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Danh sách stopword tiếng Anh:\n",
            "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_stopword(word, lang='english'):\n",
        "    return word.lower() in set(stopwords.words(lang))\n",
        "print(\"\\nKiểm tra từ 'the' có phải stopword không:\", is_stopword('the'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7U7tGkvSMKp",
        "outputId": "c1d902d6-481d-440a-cc4f-62c3df9e52d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Kiểm tra từ 'the' có phải stopword không: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nKiểm tra từ 'experient' có phải stopword không:\", is_stopword('experient'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGtYD5DlSTRD",
        "outputId": "9aebee05-6966-47d0-fd92-e897b415c16c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Kiểm tra từ 'experient' có phải stopword không: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "def remove_stopwords(text, lang='english'):\n",
        "    words = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words(lang))\n",
        "    return ' '.join([word for word in words if word.lower() not in stop_words])\n",
        "\n",
        "text = \"This is a simple example demonstrating stopword removal.\"\n",
        "print(\"\\nVăn bản sau khi loại bỏ stopword:\")\n",
        "print(remove_stopwords(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Az_PmATSlTu",
        "outputId": "94e19c1b-9cef-4347-a767-9faff140920b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Văn bản sau khi loại bỏ stopword:\n",
            "simple example demonstrating stopword removal .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = [\"this\", \"is\", \"an\", \"example\", \"of\", \"stopword\", \"removal\"]\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in word_list if word.lower() not in stop_words]\n",
        "print(\"\\nDanh sách từ sau khi loại bỏ stopword:\", filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u5R1HnkSrt2",
        "outputId": "f082c88d-a4ac-4c97-d0d2-8fa7bae3faa7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Danh sách từ sau khi loại bỏ stopword: ['example', 'stopword', 'removal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_meaning(word):\n",
        "    synsets = wordnet.synsets(word)\n",
        "    return [(syn.name(), syn.definition()) for syn in synsets] if synsets else \"Không tìm thấy định nghĩa.\"\n",
        "\n",
        "print(\"\\nĐịnh nghĩa của từ 'car':\")\n",
        "print(get_word_meaning('car'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBCM0iBYS8FX",
        "outputId": "dd7cebda-ad5b-4b6c-b07e-373daf3b82b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Định nghĩa của từ 'car':\n",
            "[('car.n.01', 'a motor vehicle with four wheels; usually propelled by an internal combustion engine'), ('car.n.02', 'a wheeled vehicle adapted to the rails of railroad'), ('car.n.03', 'the compartment that is suspended from an airship and that carries personnel and the cargo and the power plant'), ('car.n.04', 'where passengers ride up and down'), ('cable_car.n.01', 'a conveyance for passengers or freight on a cable railway')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_synonyms_antonyms(word):\n",
        "    synonyms = set()\n",
        "    antonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "            if lemma.antonyms():\n",
        "                antonyms.add(lemma.antonyms()[0].name())\n",
        "    return synonyms, antonyms\n",
        "\n",
        "print(\"\\nTừ đồng nghĩa và trái nghĩa của 'good':\")\n",
        "print(get_synonyms_antonyms('good'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5t3KwbCTAg-",
        "outputId": "6636c18f-6833-4422-ebb6-314aee95c7b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Từ đồng nghĩa và trái nghĩa của 'good':\n",
            "({'effective', 'in_effect', 'skilful', 'in_force', 'estimable', 'right', 'unspoiled', 'beneficial', 'sound', 'well', 'ripe', 'proficient', 'soundly', 'honest', 'full', 'goodness', 'serious', 'unspoilt', 'trade_good', 'adept', 'thoroughly', 'upright', 'secure', 'salutary', 'good', 'dependable', 'just', 'skillful', 'practiced', 'expert', 'near', 'undecomposed', 'safe', 'respectable', 'commodity', 'dear', 'honorable'}, {'bad', 'badness', 'ill', 'evil', 'evilness'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "def tag_pos(text):\n",
        "    words = word_tokenize(text)\n",
        "    return pos_tag(words)\n",
        "\n",
        "print(\"\\nGán nhãn từ loại:\")\n",
        "print(tag_pos(\"The quick brown fox jumps over the lazy dog\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPvMmRfWTC3C",
        "outputId": "d88b8000-3268-4a5f-f0bc-9dd24038f379"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gán nhãn từ loại:\n",
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similarity(word1, word2):\n",
        "    syn1 = wordnet.synsets(word1, pos=wordnet.NOUN)\n",
        "    syn2 = wordnet.synsets(word2, pos=wordnet.NOUN)\n",
        "    if syn1 and syn2 and syn1[0].wup_similarity(syn2[0]) is not None:\n",
        "        return syn1[0].wup_similarity(syn2[0])\n",
        "    return \"Không có dữ liệu để so sánh.\"\n",
        "\n",
        "print(\"\\nMức độ giống nhau giữa 'car' và 'automobile':\", get_similarity('car', 'automobile'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97unjx7JTGE2",
        "outputId": "6fedaa37-d7ca-4568-a9bf-22c30dd7fbfe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mức độ giống nhau giữa 'car' và 'automobile': 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMức độ giống nhau giữa 'run' và 'jog':\", get_similarity('run', 'jog'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoSH_ICiTWV9",
        "outputId": "6b706777-d781-4501-c706-465ef8fe4fd7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mức độ giống nhau giữa 'run' và 'jog': 0.23529411764705882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_names():\n",
        "    male_names = names.words('male.txt')\n",
        "    female_names = names.words('female.txt')\n",
        "    return len(male_names), len(female_names)\n",
        "\n",
        "print(\"\\nSố lượng tên nam và nữ trong tập dữ liệu:\")\n",
        "print(count_names())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2LBZu95Tpnv",
        "outputId": "6228c47a-1e2b-4d2b-fdf1-3dd130e9fa1e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Số lượng tên nam và nữ trong tập dữ liệu:\n",
            "(2943, 5001)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_names():\n",
        "    male_names = names.words('male.txt')\n",
        "    female_names = names.words('female.txt')\n",
        "    combined = random.sample(male_names, 5) + random.sample(female_names, 5)\n",
        "    random.shuffle(combined)\n",
        "    return combined\n",
        "\n",
        "print(\"\\nDanh sách tên kết hợp ngẫu nhiên:\")\n",
        "print(combine_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOktgkXPTtdu",
        "outputId": "001aa450-d13d-4bf4-e2f3-6e8a6733385e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Danh sách tên kết hợp ngẫu nhiên:\n",
            "['Selena', 'Moses', 'Jean-Christophe', 'Aloisia', 'Sapphire', 'Renae', 'Leonidas', 'Nickolas', 'Kristos', 'Talyah']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_last_letters():\n",
        "    male_names = names.words('male.txt')\n",
        "    female_names = names.words('female.txt')\n",
        "    last_letters = [(name, name[-1]) for name in male_names[:5] + female_names[:5]]\n",
        "    return last_letters\n",
        "\n",
        "print(\"\\nDanh sách ký tự cuối của một số tên:\")\n",
        "print(extract_last_letters())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yedklkU-Twki",
        "outputId": "296afe6b-5313-4fcc-ed49-1242adc9098e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Danh sách ký tự cuối của một số tên:\n",
            "[('Aamir', 'r'), ('Aaron', 'n'), ('Abbey', 'y'), ('Abbie', 'e'), ('Abbot', 't'), ('Abagael', 'l'), ('Abagail', 'l'), ('Abbe', 'e'), ('Abbey', 'y'), ('Abbi', 'i')]\n"
          ]
        }
      ]
    }
  ]
}